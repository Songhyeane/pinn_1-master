{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 단면적 계산\n",
    "def cal_area(center_a,center_b,d,theta_1,theta_2,R):\n",
    "\n",
    "    try :\n",
    "        theta = theta_1 - theta_2\n",
    "\n",
    "        point_1 = center_a +(center_b*center_a)/(R*tf.sin(theta_1))\n",
    "\n",
    "        point_2 = center_a +(center_b*(center_a-d))/(R*tf.sin(theta_2))\n",
    "\n",
    "        fan_shape = (1/2) * theta * (pow(R,2))\n",
    "\n",
    "        triangle_1 = (1/2)  * (0-point_1) * (R*tf.sin(theta_1)+center_b)\n",
    "\n",
    "        triangle_2 = (1/2)  * (d - point_2) * (R*tf.sin(theta_2)+center_b)\n",
    "\n",
    "        triangle_3 = (1/2)  * (point_2 - point_1) * (0-center_b)\n",
    "\n",
    "        area = fan_shape - triangle_1 + triangle_2 - triangle_3\n",
    "\n",
    "    except :\n",
    "        area = 0\n",
    "\n",
    "    # print(f'theta_1: {math.degrees(theta_1)} theta_2: {math.degrees(theta_2)} theta: {math.degrees(theta)}')\n",
    "\n",
    "    return area"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:22:48.404395200Z",
     "start_time": "2023-05-25T13:22:48.389347500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:22:52.932216500Z",
     "start_time": "2023-05-25T13:22:49.342117800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5.3757167e-08]], shape=(1, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow and NumPy\n",
    "# 초기 변수들 지정\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# Set data type\n",
    "DTYPE='float64'\n",
    "tf.keras.backend.set_floatx(DTYPE)\n",
    "\n",
    "# Define contact line velocity\n",
    "# theta_0 : equilibrium contact angle\n",
    "# theta_d : dynamic contact angle\n",
    "def fun_contact_line_velocity( f_c,i_t,theta_0, theta_d ):\n",
    "    one = tf.constant(1, dtype=tf.float64)\n",
    "    return -f_c*i_t*(-tf.cos(theta_0)+tf.cos(theta_d))\n",
    "# Set constants\n",
    "pi = tf.constant(np.pi, dtype=tf.float64)\n",
    "p_f_c = tf.constant(-2.02, dtype=tf.float64) # positive_friction_coefficient\n",
    "n_f_c = tf.constant(-5.64, dtype=tf.float64) # nagative_friction_coefficient\n",
    "i_t = tf.constant(7.6408/1000, dtype=tf.float64) #interfacial tension between the two liquids\n",
    "d = tf.constant(0.321/1000, dtype=tf.float64) #gab\n",
    "\n",
    "thetal_0 = tf.constant(np.deg2rad(94), dtype=tf.float64)\n",
    "thetal_d = tf.constant(np.deg2rad(55), dtype=tf.float64)\n",
    "thetar_0 = tf.constant(np.deg2rad(59),dtype=tf.float64)\n",
    "thetar_d = tf.constant(np.deg2rad(109),dtype=tf.float64)\n",
    "\n",
    "# 반지름\n",
    "r_0 = tf.constant(np.deg2rad(109), dtype=tf.float64)\n",
    "# 원의 중심 x좌표\n",
    "cneter_a = tf.constant(-0.0000566758, dtype=tf.float64)\n",
    "# 원의 중심 y좌표\n",
    "cneter_b = tf.constant(-0.0006874250504951296, dtype=tf.float64)\n",
    "\n",
    "#  세타1 좌표\n",
    "theta1_0 = tf.constant(np.pi-np.deg2rad(94),dtype=tf.float64)\n",
    "#  세타2 좌표\n",
    "theta2_0 =  thetar_0\n",
    "\n",
    "vl = tf.constant(-fun_contact_line_velocity(n_f_c ,i_t,thetal_0, thetal_d ),shape=(1,1) , dtype=tf.float64)\n",
    "vr = tf.constant(-fun_contact_line_velocity(p_f_c ,i_t,thetar_0 , thetar_d ),shape=(1,1) , dtype=tf.float64)\n",
    "\n",
    "# initial_data = [a0 ,b0,r0 ,theta_l0,theta_r0 ]\n",
    "# cal_area_theta(center_a,center_b,d,theta_l,theta_r,R):\n",
    "initial_area = tf.constant(5.375716695978319e-08,shape=(1,1) , dtype=tf.float64)\n",
    "print(initial_area)\n",
    "#thetar_d = tf.constant(initial_area, dtype=tf.float64)\n",
    "\n",
    "# Define residual of the condition\n",
    "def fun_r(yl_t , yr_t ,vl,vr,area_t ):\n",
    "    return ((yl_t-vl) + (yr_t-vr)+area_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.27272500e-06]\n",
      " [8.12988319e-06]\n",
      " [1.36279060e-05]\n",
      " ...\n",
      " [2.79928773e-02]\n",
      " [2.79933925e-02]\n",
      " [2.79937181e-02]], shape=(10000, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝 데이터(t)\n",
    "# Set random seed for reproducible results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# 시간(0~0.0280초까지)\n",
    "t_data = tf.random.uniform(shape=[1,10000],minval=0.0,maxval=0.0280, dtype=DTYPE)\n",
    "t_data = tf.reshape(t_data,shape=(-1,1))\n",
    "\n",
    "t_data = tf.constant(t_data,dtype=DTYPE)\n",
    "# 정렬( 시계열 데이터 이기 때문)\n",
    "t_data = tf.sort(t_data,axis=0)\n",
    "print(t_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:22:55.930584700Z",
     "start_time": "2023-05-25T13:22:55.892097800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 모델 구축\n",
    "def init_model(num_hidden_layers=8, num_neurons_per_layer=20):\n",
    "    # Initialize a feedforward neural network\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Input is one-dimensional (time)\n",
    "    model.add(tf.keras.Input(1,))\n",
    "\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(num_neurons_per_layer,\n",
    "            activation=tf.keras.activations.get('tanh'),\n",
    "            input_dim=t_data.shape[1],\n",
    "            kernel_initializer='glorot_normal'))\n",
    "\n",
    "    # Output is one-dimensional (center_a , center_b , R , theat_l , thetah_r)\n",
    "    model.add(tf.keras.layers.Dense(5,))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:22:56.966276Z",
     "start_time": "2023-05-25T13:22:56.934360300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get residual\n",
    "def get_r(model, t_data):\n",
    "\n",
    "    # A tf.GradientTape is used to compute derivatives in TensorFlow\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Split t to compute partial derivatives\n",
    "        t = t_data\n",
    "        # Variables t are watched during tape\n",
    "        tape.watch(t)\n",
    "\n",
    "        # 아웃풋을 a,b,R,theta_1,theta_2로 각각 분리\n",
    "        u = model(t_data)\n",
    "        a = tf.reshape(u[:,0],shape=(-1,1))\n",
    "        b = tf.reshape(u[:,1],shape=(-1,1))\n",
    "        R = tf.reshape(u[:,2],shape=(-1,1))\n",
    "        theta_1 =tf.reshape(u[:,3],shape=(-1,1))\n",
    "        theta_2 = tf.reshape(u[:,4],shape=(-1,1))\n",
    "\n",
    "        # get area\n",
    "        area = cal_area(a,b,d,theta_1,theta_2,R)\n",
    "\n",
    "    # get gradient\n",
    "    a_t = tape.gradient(a,t)\n",
    "    b_t = tape.gradient(b,t)\n",
    "    R_t = tape.gradient(R,t)\n",
    "    theta_1_t = tape.gradient(theta_1,t)\n",
    "    theta_2_t = tape.gradient(theta_2,t)\n",
    "    area_t = tape.gradient(area, t)\n",
    "\n",
    "\n",
    "    yl_t = R_t*tf.sin(theta_1)+R*tf.cos(theta_1)*theta_1_t +b_t\n",
    "    yr_t = R_t*tf.sin(theta_2)+R*tf.cos(theta_2)*theta_2_t +b_t\n",
    "\n",
    "\n",
    "    del tape\n",
    "\n",
    "    return fun_r(yl_t , yr_t ,vl ,vr,area_t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:22:57.802452Z",
     "start_time": "2023-05-25T13:22:57.775814300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def compute_loss(model,t_data):\n",
    "\n",
    "\n",
    "    # Compute phi^r\n",
    "    r = get_r(model, t_data)\n",
    "    phi_r = tf.reduce_mean(tf.square(r))\n",
    "\n",
    "    # Initialize loss - version1\n",
    "    t_0 = tf.zeros((1,1))\n",
    "\n",
    "    # Add phi^0 and phi^b to the loss\n",
    "    # u = model(t_0)\n",
    "    # pred_a = tf.reshape(u[:,0],shape=(-1,1))\n",
    "    # pred_b = tf.reshape(u[:,1],shape=(-1,1))\n",
    "    # pred_R = tf.reshape(u[:,2],shape=(-1,1))\n",
    "    # pred_theta_1 =tf.reshape(u[:,3],shape=(-1,1))\n",
    "    # pred_theta_2 = tf.reshape(u[:,4],shape=(-1,1))\n",
    "    # pred_pred_area_0 = cal_area(pred_a,pred_b,d,pred_theta_1,pred_theta_2,pred_R)\n",
    "    # loss =phi_r+tf.reduce_mean(tf.square(pred_pred_area_0 -initial_area))\n",
    "\n",
    "    # version2 -> 학습 초기에는 t=0일때 [0,0,0,0,0] 아웃풋이 나오는데 이의 단면적을 계산하면 nan이 나옴\n",
    "\n",
    "\n",
    "    # Initialize loss - version2\n",
    "    #loss = phi_r\n",
    "\n",
    "    # Add phi^0 and phi^b to the loss\n",
    "    u = model(t_data)\n",
    "    pred_a = tf.reshape(u[:,0],shape=(-1,1))\n",
    "    pred_b = tf.reshape(u[:,1],shape=(-1,1))\n",
    "    pred_R = tf.reshape(u[:,2],shape=(-1,1))\n",
    "    pred_theta_1 =tf.reshape(u[:,3],shape=(-1,1))\n",
    "    pred_theta_2 = tf.reshape(u[:,4],shape=(-1,1))\n",
    "    pred_pred_area_0 = cal_area(pred_a,pred_b,d,pred_theta_1,pred_theta_2,pred_R)\n",
    "    loss =phi_r+tf.reduce_mean(tf.square(pred_pred_area_0 -initial_area))\n",
    "\n",
    "\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:22:59.956187Z",
     "start_time": "2023-05-25T13:22:59.926506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_grad(model,t_data):\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # This tape is for derivatives with\n",
    "        # respect to trainable variables\n",
    "        tape.watch(model.trainable_variables)\n",
    "        loss = compute_loss(model,t_data)\n",
    "\n",
    "    g = tape.gradient(loss, model.trainable_variables)\n",
    "    del tape\n",
    "\n",
    "    return loss, g"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:23:01.368444300Z",
     "start_time": "2023-05-25T13:23:01.354434100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Initialize model aka u_\\theta\n",
    "model = init_model()\n",
    "\n",
    "# We choose a piecewise decay of the learning rate, i.e., the\n",
    "# step size in the gradient descent type algorithm\n",
    "# the first 1000 steps use a learning rate of 0.01\n",
    "# from 1000 - 3000: learning rate = 0.001\n",
    "# from 3000 onwards: learning rate = 0.0005\n",
    "\n",
    "lr = tf.keras.optimizers.schedules.PiecewiseConstantDecay([1000,3000],[1e-2,1e-3,5e-4])\n",
    "\n",
    "# Choose the optimizer\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:23:01.930083100Z",
     "start_time": "2023-05-25T13:23:01.828151100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 00000: loss = 1.17260698e-02\n",
      "It 00050: loss = 8.63090997e-05\n",
      "It 00100: loss = 1.25146999e-06\n",
      "It 00150: loss = 7.58080489e-07\n",
      "It 00200: loss = 7.38395991e-07\n",
      "It 00250: loss = 7.28109235e-07\n",
      "It 00300: loss = 7.16845646e-07\n",
      "It 00350: loss = 7.04675102e-07\n",
      "It 00400: loss = 6.91701660e-07\n",
      "It 00450: loss = 6.78016550e-07\n",
      "It 00500: loss = 6.63701581e-07\n",
      "It 00550: loss = 6.48831432e-07\n",
      "It 00600: loss = 6.33475142e-07\n",
      "It 00650: loss = 6.17697119e-07\n",
      "It 00700: loss = 6.01557832e-07\n",
      "It 00750: loss = 5.85114312e-07\n",
      "It 00800: loss = 5.68420505e-07\n",
      "It 00850: loss = 5.51527545e-07\n",
      "It 00900: loss = 5.34483952e-07\n",
      "It 00950: loss = 5.17335790e-07\n",
      "It 01000: loss = 5.00126787e-07\n",
      "It 01050: loss = 4.98069193e-07\n",
      "It 01100: loss = 4.96261579e-07\n",
      "It 01150: loss = 4.94392670e-07\n",
      "It 01200: loss = 4.92462392e-07\n",
      "It 01250: loss = 4.90470648e-07\n",
      "It 01300: loss = 4.88417313e-07\n",
      "It 01350: loss = 4.86302238e-07\n",
      "It 01400: loss = 4.84125257e-07\n",
      "It 01450: loss = 4.81886188e-07\n",
      "It 01500: loss = 4.79584838e-07\n",
      "It 01550: loss = 4.77221005e-07\n",
      "It 01600: loss = 4.74794481e-07\n",
      "It 01650: loss = 4.72305056e-07\n",
      "It 01700: loss = 4.69752518e-07\n",
      "It 01750: loss = 4.67136659e-07\n",
      "It 01800: loss = 4.64457275e-07\n",
      "It 01850: loss = 4.61714167e-07\n",
      "It 01900: loss = 4.58907148e-07\n",
      "It 01950: loss = 4.56036042e-07\n",
      "It 02000: loss = 4.53100685e-07\n",
      "It 02050: loss = 4.50100932e-07\n",
      "It 02100: loss = 4.47036653e-07\n",
      "It 02150: loss = 4.43907741e-07\n",
      "It 02200: loss = 4.40714110e-07\n",
      "It 02250: loss = 4.37455699e-07\n",
      "It 02300: loss = 4.34132476e-07\n",
      "It 02350: loss = 4.30744435e-07\n",
      "It 02400: loss = 4.27291604e-07\n",
      "It 02450: loss = 4.23774044e-07\n",
      "It 02500: loss = 4.20191849e-07\n",
      "It 02550: loss = 4.16545156e-07\n",
      "It 02600: loss = 4.12834138e-07\n",
      "It 02650: loss = 4.09059012e-07\n",
      "It 02700: loss = 4.05220041e-07\n",
      "It 02750: loss = 4.01317532e-07\n",
      "It 02800: loss = 3.97351843e-07\n",
      "It 02850: loss = 3.93323384e-07\n",
      "It 02900: loss = 3.89232616e-07\n",
      "It 02950: loss = 3.85080059e-07\n",
      "It 03000: loss = 3.80866287e-07\n",
      "It 03050: loss = 3.78681375e-07\n",
      "It 03100: loss = 3.76495718e-07\n",
      "It 03150: loss = 3.74266224e-07\n",
      "It 03200: loss = 3.71992517e-07\n",
      "It 03250: loss = 3.69674230e-07\n",
      "It 03300: loss = 3.67311014e-07\n",
      "It 03350: loss = 3.64902535e-07\n",
      "It 03400: loss = 3.62448475e-07\n",
      "It 03450: loss = 3.59948535e-07\n",
      "It 03500: loss = 3.57402433e-07\n",
      "It 03550: loss = 3.54809911e-07\n",
      "It 03600: loss = 3.52170730e-07\n",
      "It 03650: loss = 3.49484676e-07\n",
      "It 03700: loss = 3.46751561e-07\n",
      "It 03750: loss = 3.43971220e-07\n",
      "It 03800: loss = 3.41143521e-07\n",
      "It 03850: loss = 3.38268356e-07\n",
      "It 03900: loss = 3.35345652e-07\n",
      "It 03950: loss = 3.32375367e-07\n",
      "It 04000: loss = 3.29357494e-07\n",
      "It 04050: loss = 3.26292062e-07\n",
      "It 04100: loss = 3.23179137e-07\n",
      "It 04150: loss = 3.20018824e-07\n",
      "It 04200: loss = 3.16811270e-07\n",
      "It 04250: loss = 3.13556666e-07\n",
      "It 04300: loss = 3.10255244e-07\n",
      "It 04350: loss = 3.06907285e-07\n",
      "It 04400: loss = 3.03513117e-07\n",
      "It 04450: loss = 3.00073118e-07\n",
      "It 04500: loss = 2.96587718e-07\n",
      "It 04550: loss = 2.93057398e-07\n",
      "It 04600: loss = 2.89482697e-07\n",
      "It 04650: loss = 2.85864208e-07\n",
      "It 04700: loss = 2.82202583e-07\n",
      "It 04750: loss = 2.78498533e-07\n",
      "It 04800: loss = 2.74752833e-07\n",
      "It 04850: loss = 2.70966317e-07\n",
      "It 04900: loss = 2.67139887e-07\n",
      "It 04950: loss = 2.63274508e-07\n",
      "It 05000: loss = 2.59371214e-07\n",
      "\n",
      "Computation time: 384.2427945137024 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# Define one training step as a TensorFlow function to increase speed of training\n",
    "@tf.function\n",
    "def train_step():\n",
    "    # Compute current loss and gradient w.r.t. parameters\n",
    "    loss, grad_theta = get_grad(model,t_data)\n",
    "\n",
    "    # Perform gradient descent step\n",
    "    optim.apply_gradients(zip(grad_theta, model.trainable_variables))\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Number of training epochs\n",
    "N = 5000\n",
    "hist = []\n",
    "\n",
    "# Start timer\n",
    "t0 = time()\n",
    "\n",
    "for i in range(N+1):\n",
    "\n",
    "    loss = train_step()\n",
    "\n",
    "    # Append current loss to hist\n",
    "    hist.append(loss.numpy())\n",
    "\n",
    "    # Output current loss after 50 iterates\n",
    "    if i%50 == 0:\n",
    "        print('It {:05d}: loss = {:10.8e}'.format(i,loss))\n",
    "\n",
    "# Print computation time\n",
    "print('\\nComputation time: {} seconds'.format(time()-t0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:29:26.617591700Z",
     "start_time": "2023-05-25T13:23:02.359104500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(281, 5), dtype=float64, numpy=\narray([[ 0.62932965, -0.3389331 , -0.57900239,  0.52310261,  0.29269733],\n       [ 0.62934327, -0.33892827, -0.57901045,  0.52309935,  0.29270861],\n       [ 0.6293569 , -0.33892344, -0.57901852,  0.52309609,  0.29271989],\n       ...,\n       [ 0.63314754, -0.33756819, -0.5812427 ,  0.52216773,  0.29589035],\n       [ 0.63316138, -0.3375632 , -0.58125075,  0.52216426,  0.29590205],\n       [ 0.63317521, -0.33755821, -0.5812588 ,  0.52216079,  0.29591374]])>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=tf.linspace(0.0, 0.0280, 281)\n",
    "test_data = tf.reshape(test_data,shape=(-1,1))\n",
    "model(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T13:29:32.230115300Z",
     "start_time": "2023-05-25T13:29:32.156304400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u=model(tf.zeros((1,1)))\n",
    "print(u)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
